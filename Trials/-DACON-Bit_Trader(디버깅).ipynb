{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "data_path = '../Big_Data/[DACON]Bit_Trader'\n",
    "train_x_df = pd.read_csv(data_path  + \"/train_x_df.csv\")\n",
    "train_y_df = pd.read_csv(data_path  + \"/train_y_df.csv\")\n",
    "test_x_df = pd.read_csv(data_path  + \"/test_x_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 관계 상, train 데이터 상단의 300개 샘플를 구성하여 학습 및 추론\n",
    "train_x_df = train_x_df[train_x_df.sample_id < 300]\n",
    "\n",
    "#train_x_df와 train_y_df time열을 기준으로 concatenate하기(일단 생략하고 x_train만 가지고 학습 진행할 것. 1380 + 120 = 1500개 데이터로 학습하나 138만 가지고 학습하나 모델의 성능에 큰 차이를 미치지는 않을 것으로 추측하기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 받은 2차원 데이터 프레임을 3차원 numpy array로 변경하는 함수\n",
    "def df2d_to_array3d(df_2d):\n",
    "    feature_size = df_2d.iloc[:,2:].shape[1]\n",
    "    time_size = len(df_2d.time.value_counts())\n",
    "    sample_size = len(df_2d.sample_id.value_counts())\n",
    "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n",
    "    return array_3d\n",
    "\n",
    "\n",
    "# 2차원 DF LSTM으로 학습하기 위해 3차원으로 변환시키기\n",
    "train_x_array = df2d_to_array3d(train_x_df)   #(300, 1380, 10)\n",
    "# valid_x_array = df2d_to_array3d(valid_x_df)\n",
    "test_x_array = df2d_to_array3d(test_x_df)     #(529, 1380, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구성(op1: many-to-one model, op2: many-to-many model(출력값 모양 바꾸고 return_sequences = True))\n",
    "seq_len = 120\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', return_sequences=False, input_shape = [seq_len, 1]))\n",
    "model.add(Dense(240))\n",
    "model.add(Dense(1))\n",
    "model.add(Reshape([1, 1]))  #120개의 open값 입력되어 121번째 open값 '하나' 예측\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_array데이터로 시계열 Windows 만들기\n",
    "for idx in tqdm(range(train_x_array.shape[0])):\n",
    "    seq_len = 120  # window_size와 같은 개념\n",
    "    sequence_length = seq_len + 1\n",
    "\n",
    "    windows = []\n",
    "    for index in range(1380 - sequence_length):\n",
    "        windows.append(train_x_array[idx, :, 1][index: index + sequence_length])\n",
    "\n",
    "    # x_train, y_train 데이터 구성\n",
    "    windows = np.array(windows) #1329 * 121의 2차원 배열\n",
    "    x_train = windows[:, :-1]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    y_train = windows[:, -1]\n",
    "\n",
    "    #Fit\n",
    "    model.fit(x_train, y_train, validation_split=0.1, epochs = 3, batch_size = 1380) #batch_size = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실값 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto_Regressive한 Prediction 및 valid_pred_array에 예측 결과 기록\n",
    "\n",
    "# 1) test_pred_array{예측값 모아두는 3차원 배열(120*1 2차원 배열 529개)} 만들기\n",
    "test_pred_array = np.zeros([len(test_x_array), 120, 1])\n",
    "\n",
    "# 2) test_x_array로 시계열 Windows 만들기 -> 데이터셋 구성 -> 모델 학습 ||| 예측 -> test_pred_array에 기록 -> window_3d의 첫번째 값 삭제 -> test_pred_array와 window_3d 병합 -> model.predict()에 넣어 예측 -> ***\n",
    "\n",
    "# test_x_array로 시계열 Windows 만들기\n",
    "for idx in tqdm(range(test_x_array.shape[0])):  # 529번\n",
    "    seq_len = 120\n",
    "    sequence_length = seq_len + 1\n",
    "\n",
    "    windows = []\n",
    "    for index in range(1380 - sequence_length):\n",
    "        windows.append(test_x_array[idx, :, 1][index: index + sequence_length])\n",
    "\n",
    "    # x_test, y_test 데이터셋 구성\n",
    "    windows = np.array(windows)  # 1329 * 121의 2차원 배열\n",
    "    x_test = windows[:, :-1]\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "    y_test = windows[:, -1]\n",
    "\n",
    "    # Fit\n",
    "    model.fit(x_test, y_test, epochs=3, batch_size=1380, verbose=1)\n",
    "\n",
    "    # test_x_array Windows 중 마지막 윈도우 추출해서 3차원 변환시켜 LSTM모델에 넣고 Predict\n",
    "    window = windows[-1, :-1]\n",
    "    window_3d = np.reshape(window, (1, window.shape[0], 1))\n",
    "    for m in range(window.shape[0]):\n",
    "        # model.predict()에 window_3d 넣어 예측\n",
    "        pred = model.predict(window_3d)\n",
    "\n",
    "        # 120분 중 처음 1분 예측값 test_pred_array에 기록\n",
    "        test_pred_array[idx, m, :] = pred\n",
    "\n",
    "        # window_3d의 첫번째 분 값은 삭제한 window_3d_2nd 구성\n",
    "        window_3d_2nd = window_3d[0, 1:, :]  # 119개\n",
    "\n",
    "        # pred_target(prediction할 때마다 나오는 각각의 예측값들) 1차원 -> 2차원으로 구성\n",
    "        pred_target = test_pred_array[idx, m, :]\n",
    "        pred_target = np.reshape(pred_target, (pred_target.shape[0], 1))\n",
    "\n",
    "        # test_pred_array와 window_3d_2nd 병합하여 모델에 입력할 새로운 window_3d 재구성\n",
    "        window_3d = np.concatenate((window_3d_2nd, pred_target), axis=0)\n",
    "        window_3d = window_3d.T\n",
    "        window_3d = np.reshape(window_3d, (window_3d.shape[0], window_3d.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred_array에 채워진 (sample_id x번째 자료에 대한)120분 예측값 확인\n",
    "x = 528\n",
    "print(test_pred_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 및 로드\n",
    "model.save('./my_model.h5')\n",
    "model = tf.keras.models.load_model('./my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매수 시점, 매수 비율 표 만들기\n",
    "# 1) train_pred_array 3차원에서 2차원으로 바꾸기\n",
    "pred_array_2d = np.zeros([test_pred_array.shape[0], 120])\n",
    "\n",
    "for idx in tqdm(range(test_pred_array.shape[0])):\n",
    "    pred_array_2d[idx, :] = test_pred_array[idx, :, 0]\n",
    "\n",
    "# 2) 예측값을 재해석하여 submission 표를 작성하는 함수 정의\n",
    "def array_to_submission(pred_array):\n",
    "    submission = pd.DataFrame(np.zeros([pred_array.shape[0], 2], np.int64),\n",
    "                              columns=['buy_quantity', 'sell_time'])\n",
    "    submission = submission.reset_index()\n",
    "    buy_price = []\n",
    "    for idx, sell_time in enumerate(np.argmax(pred_array, axis=1)):\n",
    "        buy_price.append(pred_array[idx, sell_time])\n",
    "    buy_price = np.array(buy_price)\n",
    "    submission.loc[:, 'buy_quantity'] = (buy_price > 1.15) * 1\n",
    "    submission['sell_time'] = np.argmax(pred_array, axis=1)\n",
    "    submission.columns = ['sample_id', 'buy_quantity', 'sell_time']\n",
    "    return submission\n",
    "\n",
    "final_submission = array_to_submission(pred_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 300가지 sample에 대해 _가지 case에서 115% 이상 상승한다고 추론함.\n",
    "final_submission.buy_quantity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_submission csv파일로 저장\n",
    "final_submission.to_csv('./submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가: 샘플에서 실제값과 예측값 비교\n",
    "# 1) 입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 정의\n",
    "def plot_series(x_series, y_series):\n",
    "    plt.plot(x_series, label = 'input_series')\n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)),\n",
    "             y_series, label = 'output_series')\n",
    "    plt.axhline(1, c = 'red')\n",
    "    plt.legend()\n",
    "\n",
    "# 2) train data 중 sample_id idx에 해당하는 x_series로 모델을 학습한 후 y_sereis를 추론\n",
    "idx = 500\n",
    "x_series = test_x_array[idx,:,1]\n",
    "\n",
    "plt.plot(x_series)\n",
    "plt.plot(np.arange(1380, 1380+120), test_pred_array[idx], label = 'prediction')\n",
    "plt.legend()\n",
    "plt.show() # 한눈에 봐도 학습이 전혀 되지 않고 있다는 것 알 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
