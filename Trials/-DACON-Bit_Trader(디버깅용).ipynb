{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "soviet-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spare-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "data_path = '../Big_Data/[DACON]Bit_Trader'\n",
    "train_x_df = pd.read_csv(data_path  + \"/train_x_df.csv\")\n",
    "train_y_df = pd.read_csv(data_path  + \"/train_y_df.csv\")\n",
    "test_x_df = pd.read_csv(data_path  + \"/test_x_df.csv\")\n",
    "\n",
    "# 시간 관계 상, train 데이터 상단의 300개 샘플를 구성하여 학습 및 추론\n",
    "train_x_df = train_x_df[train_x_df.sample_id < 300]\n",
    "train_y_df = train_x_df[train_y_df.sample_id < 300]\n",
    "#train_x_df와 train_y_df time열을 기준으로 concatenate하기(일단 생략하고 x_train만 가지고 학습 진행할 것. 1380 + 120 = 1500개 데이터로 학습하나 1380개만 가지고 학습하나 모델의 성능에 큰 차이를 미치지는 않을 것으로 추측하기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "powerful-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 받은 2차원 데이터 프레임을 3차원 numpy array로 변경하는 함수\n",
    "def df2d_to_array3d(df_2d):\n",
    "    feature_size = df_2d.iloc[:,2:].shape[1]\n",
    "    time_size = len(df_2d.time.value_counts())\n",
    "    sample_size = len(df_2d.sample_id.value_counts())\n",
    "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n",
    "    return array_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jewish-webster",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 360000 into shape (27,1380,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d7c02230b4fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 2차원 DF LSTM으로 학습하기 위해 3차원으로 변환시키기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_x_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2d_to_array3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_df\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#(300, 1380, 10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_y_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2d_to_array3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y_df\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#(300, 120, 10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_x_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2d_to_array3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x_df\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#(529, 1380, 10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8ac136e38c5c>\u001b[0m in \u001b[0;36mdf2d_to_array3d\u001b[1;34m(df_2d)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtime_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msample_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0marray_3d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_3d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 360000 into shape (27,1380,10)"
     ]
    }
   ],
   "source": [
    "# 2차원 DF LSTM으로 학습하기 위해 3차원으로 변환시키기\n",
    "train_x_array = df2d_to_array3d(train_x_df)   #(300, 1380, 10)\n",
    "train_y_array = df2d_to_array3d(train_y_df)   #(300, 120, 10)\n",
    "test_x_array = df2d_to_array3d(test_x_df)     #(529, 1380, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구성(op1: many-to-one model, op2: many-to-many model(output 모양 바꾸기, return_sequences = True, Window이동 단위 1에서 output 크기로 변경))\n",
    "seq_len = 120\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences= True, input_shape = [seq_len, 1]))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "# model.add(Reshape([1, 1]))  #120개의 open값 입력되어 121번째 open값 '하나' 예측\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x_array에 대한 Auto_Regressive한 Prediction 및 valid_pred_array에 예측 결과 기록\n",
    "\n",
    "# 1) test_pred_array{예측값 모아두는 3차원 배열(120*1 2차원 배열 529개)} 만들기\n",
    "test_pred_array = np.zeros([len(test_x_array), 120, 1])\n",
    "\n",
    "# 2) test_x_array로 시계열 Windows 만들기 -> 데이터셋 구성 -> 모델 학습 ||| 예측 -> test_pred_array에 기록 -> window_3d의 첫번째 값 삭제 -> test_pred_array와 window_3d 병합 -> model.predict()에 넣어 예측 -> ***\n",
    "\n",
    "# test_x_array로 시계열 Windows 만들기\n",
    "ep = 10\n",
    "bs = 120\n",
    "for idx in tqdm(range(test_x_array.shape[0])):  # 529번\n",
    "    seq_len = 120\n",
    "    sequence_length = seq_len + 1\n",
    "\n",
    "    windows = []\n",
    "    for index in range(1380 - sequence_length):\n",
    "        windows.append(test_x_array[idx, :, 1][index: index + sequence_length])\n",
    "\n",
    "    # x_test, y_test 데이터셋 구성\n",
    "    windows = np.array(windows)  # 1329 * 121의 2차원 배열\n",
    "    x_test = windows[:, :-1]\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "    y_test = windows[:, -1]\n",
    "\n",
    "    # Fit\n",
    "    model.fit(x_test, y_test, epochs= ep, batch_size= bs, verbose=0)\n",
    "\n",
    "    # test_x_array Windows 중 마지막 윈도우 추출해서 3차원 변환시켜 LSTM모델에 넣고 Predict\n",
    "    window = windows[-1, :-1]\n",
    "    window_3d = np.reshape(window, (1, window.shape[0], 1))\n",
    "    for m in range(window.shape[0]):\n",
    "        # model.predict()에 window_3d 넣어 예측\n",
    "        pred = model.predict(window_3d)\n",
    "\n",
    "        # 120분 중 처음 1분 예측값 test_pred_array에 기록\n",
    "        test_pred_array[idx, m, :] = pred\n",
    "\n",
    "        # window_3d의 첫번째 분 값은 삭제한 window_3d_2nd 구성\n",
    "        window_3d_2nd = window_3d[0, 1:, :]  # 119개\n",
    "\n",
    "        # pred_target(prediction할 때마다 나오는 각각의 예측값들) 1차원 -> 2차원으로 구성\n",
    "        pred_target = test_pred_array[idx, m, :]\n",
    "        pred_target = np.reshape(pred_target, (pred_target.shape[0], 1))\n",
    "\n",
    "        # test_pred_array와 window_3d_2nd 병합하여 모델에 입력할 새로운 window_3d 재구성\n",
    "        window_3d = np.concatenate((window_3d_2nd, pred_target), axis=0)\n",
    "        window_3d = window_3d.T\n",
    "        window_3d = np.reshape(window_3d, (window_3d.shape[0], window_3d.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred_array에 채워진 (sample_id x번째 자료에 대한)120분 예측값 확인\n",
    "x = 528\n",
    "print(test_pred_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가: test_x데이터로 예측하는 방식을 입력값(train_x)에 대한 예측값과 실제값(train_y_array) 비교를 통해 평가\n",
    "# train_x_array데이터로 시계열 Windows 만들기\n",
    "for idx in tqdm(range(train_x_array.shape[0])):\n",
    "    seq_len = 120  # window_size와 같은 개념\n",
    "    sequence_length = seq_len + 1\n",
    "\n",
    "    windows = []\n",
    "    for index in range(1380 - sequence_length):\n",
    "        windows.append(train_x_array[idx, :, 1][index: index + sequence_length])\n",
    "\n",
    "    # x_train, y_train 데이터 구성\n",
    "    windows = np.array(windows) #1329 * 121의 2차원 배열\n",
    "    x_train = windows[:, :-1]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    y_train = windows[:, -1]\n",
    "\n",
    "    #Fit\n",
    "    fit = model.fit(x_train, y_train, validation_split=0.1, epochs = ep, batch_size = bs)\n",
    "    preds = fit.predict(1, 120, typ= 'levels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 샘플 훈련 성과 시각화해보기\n",
    "# 1) 입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 정의\n",
    "def plot_series(x_series, y_series):\n",
    "    plt.plot(x_series, label = 'input_series')\n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)),\n",
    "             y_series, label = 'output_series')\n",
    "    plt.axhline(1, c = 'red')\n",
    "    plt.legend()\n",
    "\n",
    "# 2) train data 중 sample_id idx에 해당하는 x_series로 모델을 학습한 후 y_series를 추론\n",
    "idx = 500\n",
    "x_series = train_x_array[idx,:,1]\n",
    "y_series = train_y_array[idx,:,1]\n",
    "plt.plot(x_series, y_series)\n",
    "plt.plot(np.arange(1380, 1380+120), preds, label = 'prediction')\n",
    "plt.legend()\n",
    "plt.show() # 한눈에 봐도 학습이 전혀 되지 않고 있다는 것 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실값 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 및 로드\n",
    "model.save('./my_model.h5')\n",
    "model = tf.keras.models.load_model('./my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매수 시점, 매수 비율 표 만들기\n",
    "# 1) train_pred_array 3차원에서 2차원으로 바꾸기\n",
    "pred_array_2d = np.zeros([test_pred_array.shape[0], 120])\n",
    "\n",
    "for idx in tqdm(range(test_pred_array.shape[0])):\n",
    "    pred_array_2d[idx, :] = test_pred_array[idx, :, 0]\n",
    "\n",
    "# 2) 예측값을 재해석하여 submission 표를 작성하는 함수 정의\n",
    "def array_to_submission(pred_array):\n",
    "    submission = pd.DataFrame(np.zeros([pred_array.shape[0], 2], np.int64),\n",
    "                              columns=['buy_quantity', 'sell_time'])\n",
    "    submission = submission.reset_index()\n",
    "    buy_price = []\n",
    "    for idx, sell_time in enumerate(np.argmax(pred_array, axis=1)):\n",
    "        buy_price.append(pred_array[idx, sell_time])\n",
    "    buy_price = np.array(buy_price)\n",
    "    submission.loc[:, 'buy_quantity'] = (buy_price > 1.15) * 1\n",
    "    submission['sell_time'] = np.argmax(pred_array, axis=1)\n",
    "    submission.columns = ['sample_id', 'buy_quantity', 'sell_time']\n",
    "    return submission\n",
    "\n",
    "final_submission = array_to_submission(pred_array_2d)\n",
    "\n",
    "# 전체 300가지 sample에 대해 _가지 case에서 115% 이상 상승한다고 추론함.\n",
    "final_submission.buy_quantity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_submission csv파일로 저장\n",
    "final_submission.to_csv('./submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-mechanics",
   "metadata": {},
   "source": [
    "# many-to-many 모델로 다시 돌려보기(input: 120, output: 10 정도?), optimizer을 rmsprop으로 설정해보기,\n",
    "# 시가에 임의의 상수 곱해서 증폭된 값으로 입력해보기\n",
    "# epoch 수 늘리고 batch_size 줄여서 다시 학습\n",
    "# LSTM 레이어 조절해보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
